{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Descarga de librerias necesarias e importaciones"
      ],
      "metadata": {
        "id": "F6JFJR5OGwqS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5yTSh0YGrCY"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers\n",
        "!pip install git+https://github.com/huggingface/speechbox\n",
        "!pip install --upgrade pyannote.audio\n",
        "!pip install speechbrain==0.5.16\n",
        "!pip install kenlm\n",
        "!pip install pyctcdecode\n",
        "!pip install sacremoses\n",
        "!pip install rouge-score\n",
        "from transformers import pipeline\n",
        "from speechbox import ASRDiarizationPipeline\n",
        "import speechbrain\n",
        "import re\n",
        "from rouge_score import rouge_scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos speech to text whisper"
      ],
      "metadata": {
        "id": "GmgPGjyrGvTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stp(audio):\n",
        "  transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-medium\", )\n",
        "  #En model podemos seleccionar el modelo de whisper que queremos usar\n",
        "  ex = transcriber(audio, return_timestamps=True)#, generate_kwargs={\"task\": \"translate\"})\n",
        "  return ex['text']\n"
      ],
      "metadata": {
        "id": "BzjJhdPCI7sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo speech to text jonatasgrosman/wav2vec2-large-xlsr-53-spanish"
      ],
      "metadata": {
        "id": "8Ih8_FbEJMud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"automatic-speech-recognition\", model=\"jonatasgrosman/wav2vec2-large-xlsr-53-spanish\")\n",
        "pipe(\"prueba.aac\")"
      ],
      "metadata": {
        "id": "MYRrW4BTJPZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo whisper en un pipeline para hacer la diarization por hablantes"
      ],
      "metadata": {
        "id": "3q6DsgmCJWqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = ASRDiarizationPipeline.from_pretrained(\"openai/whisper-tiny\", use_auth_token = \"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\")\n",
        "out = pipeline(\"/content/consulta2.wav\", return_timestamps='word')\n",
        "print(out)"
      ],
      "metadata": {
        "id": "mQ8x9EQqJcKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones que se usan para el resultado del speech to text pasarlo a un formato adecuado para la traducción y posteriormente resumen"
      ],
      "metadata": {
        "id": "FdfxbkmWJrMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_dialogo(dialogo_lista):\n",
        "    dialogo_normal = []\n",
        "    for linea in dialogo_lista:\n",
        "        speaker_texto = f\"Speaker {linea['Speaker']}: {linea['Text']}\"\n",
        "        dialogo_normal.append(speaker_texto)\n",
        "    return dialogo_normal\n",
        "\n",
        "dialogo_lista = parse_dialogo(dialogue)\n",
        "print(dialogo_lista)\n",
        "\n",
        "def generate_text(dialogue):\n",
        "    text = \"\"\n",
        "    current_speaker = None\n",
        "    for line in dialogue:\n",
        "        if current_speaker != line[\"Speaker\"]:\n",
        "            text += \". \" if text else \"\"\n",
        "            text += f\"\\nSpeaker {line['Speaker']}: {line['Text']}\"\n",
        "            current_speaker = line[\"Speaker\"]\n",
        "        else:\n",
        "            text += f\" {line['Text']}\"\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "osSIMplgJ1gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo helsinki para la traducción de español a ingles"
      ],
      "metadata": {
        "id": "L8f16zIfJ-W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translateESEN(sum):\n",
        "\n",
        "  pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\", max_length=4000)\n",
        "\n",
        "  return pipe(sum, max_length=4000)"
      ],
      "metadata": {
        "id": "2Z7CEr2IKCfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones para la utlización del summarizer y la traducción para la división del texto, debido a la limitación de los distintos transfomer en cuanto a la extensión de entrada"
      ],
      "metadata": {
        "id": "514F6MAdcATN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dividir_texto_trad(texto):\n",
        "    subconjuntos = []  # Lista para almacenar los subconjuntos\n",
        "    inicio = 0  # Inicializar el índice de inicio del subconjunto actual\n",
        "\n",
        "    while inicio < len(texto):\n",
        "        # Encontrar el índice final del subconjunto\n",
        "        fin = inicio + 512\n",
        "        if fin >= len(texto):\n",
        "            fin = len(texto)\n",
        "        else:\n",
        "            # Asegurarse de no dividir palabras\n",
        "            while fin > inicio and texto[fin] != ' ':\n",
        "                fin -= 1\n",
        "\n",
        "        subconjuntos.append(texto[inicio:fin])  # Agregar el subconjunto al resultado\n",
        "        inicio = fin   # Actualizar el índice de inicio para el próximo subconjunto\n",
        "\n",
        "    return subconjuntos\n",
        "\n",
        "def dividir_texto_sum(texto):\n",
        "  subconjunto = []\n",
        "  l = len(text.split(\"SPEAKER\")) // 3\n",
        "  te = text.split(\"SPEAKER\")\n",
        "  parte1 = te[0:l]\n",
        "  parte2 = te[l:2*l]\n",
        "  parte3 = te[2*l:]\n",
        "\n",
        "  p1 = \" \".join(parte1)\n",
        "  p2 = \" \".join(parte2)\n",
        "  p3 = \" \".join(parte3)\n",
        "\n",
        "  subconjunto.append(p1)\n",
        "  subconjunto.append(p2)\n",
        "  subconjunto.append(p3)\n",
        "\n",
        "\n",
        "  return subconjunto"
      ],
      "metadata": {
        "id": "Qd3qG9eIc1eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos de resumen en una función para las pruebas, para ir probando ir comentando y descomentantdo los distintos summarizer"
      ],
      "metadata": {
        "id": "FeTAeKdtY6go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "\n",
        "  #summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\" )\n",
        "  #summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
        "  #summarizer = pipeline(\"text2text-generation\", model=\"Saurabh91/medical_summarization-finetuned-starmpccAsclepius-Synthetic-Clinical-Notes\")\n",
        "  #summarizer = pipeline(\"summarization\", model=\"Falconsai/medical_summarization\")\n",
        "  summarizer = pipeline(\"summarization\", model=\"google-t5/t5-large\")\n",
        "\n",
        "  resumen = summarizer(text, do_sample=False)\n",
        "\n",
        "  return resumen"
      ],
      "metadata": {
        "id": "52TCFelmZDoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Helsinki para traducción es ingles a español"
      ],
      "metadata": {
        "id": "3y52Kq08bsaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translateENES(sum):\n",
        "  pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "\n",
        "  return pipe(sum)"
      ],
      "metadata": {
        "id": "MRrT1Fzubxs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para leer fichero de texto. Se utilizará para leer el fichero con el texto original, con el que se comparará el prototipo para aplicar las métricas ROUGE."
      ],
      "metadata": {
        "id": "2vaD99KidCa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leer_fichero(archivo):\n",
        "  with open(archivo, 'r') as file:\n",
        "    lineas = file.readlines()\n",
        "  source = \"\"\n",
        "  for i in lineas:\n",
        "    source = source + i\n",
        "  return source\n"
      ],
      "metadata": {
        "id": "XF6g6WNzdEYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilización de métricas rougue para la evaluación de speech to text"
      ],
      "metadata": {
        "id": "K6lrxzwDdJpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "#Parámetros que recibe el texto candidato y el texto con el que se va a comaprar.\n",
        "scores = scorer.score(texto_sin_speakers_source, texto_final_large)\n",
        "for key in scores:\n",
        "    print(f'{key}: {scores[key]}')"
      ],
      "metadata": {
        "id": "32wsHigVdPHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}